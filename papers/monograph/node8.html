<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Literature Review</TITLE>
<META NAME="description" CONTENT="Literature Review">
<META NAME="keywords" CONTENT="kmono">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="kmono.css">

<LINK REL="next" HREF="node9.html">
<LINK REL="previous" HREF="node7.html">
<LINK REL="up" HREF="node4.html">
<LINK REL="next" HREF="node9.html">
</HEAD>

<BODY >

<A NAME="tex2html300"
  HREF="node9.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html296"
  HREF="node4.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html290"
  HREF="node7.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html298"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html301"
  HREF="node9.html">Approaches</A>
<B>Up:</B> <A NAME="tex2html297"
  HREF="node4.html">Overview</A>
<B> Previous:</B> <A NAME="tex2html291"
  HREF="node7.html">Image Interpretation</A>
<BR> <P>

<!--End of Navigation Panel-->

<H1><A NAME="SECTION00430000000000000000"></A>
<A NAME="sec:scene_litsurvey"></A>
<BR>
Literature Review
</H1>

<P>
interpretation, literature
Image interpretation has been researched widely for the last couple of decades.
A major application of image
interpretation is in remote sensing which is widely used in geographical
surveys and military applications. Image interpretation also plays a
major role in biomedical science and particle physics,
where many of the
results are recorded in the form of photographs. 
The earliest available image interpretation literature dates back to
1969 [<A
 HREF="node80.html#bk_Gras_69">4</A>,<A
 HREF="node80.html#bk_Andr_69">5</A>,<A
 HREF="node80.html#bk_Nara_69">6</A>]. Research in the area of
image interpretation encompasses images related to
biomedicalinterpretation,biomedical 
applications [<A
 HREF="node80.html#pr_Hofm_85">7</A>,<A
 HREF="node80.html#jr_Sage_88">8</A>,<A
 HREF="node80.html#phd_Kars_89">9</A>,<A
 HREF="node80.html#jr_Bald_92">10</A>,<A
 HREF="node80.html#jr_Coot_94">11</A>], satellite images [<A
 HREF="node80.html#pr_Desa_92">12</A>]interpretation,satellite
images, aerial imagery interpretation,aerial images
[<A
 HREF="node80.html#bk_Naga_80">13</A>,<A
 HREF="node80.html#pr_Mcke_85">14</A>,<A
 HREF="node80.html#pr_Mcke_87">15</A>,<A
 HREF="node80.html#pr_Silb_88">16</A>,<A
 HREF="node80.html#pr_Kuan_88">17</A>,<A
 HREF="node80.html#jr_Mcke_89">18</A>,<A
 HREF="node80.html#pr_Garn_90">19</A>,<A
 HREF="node80.html#pr_Venka_90">20</A>,<A
 HREF="node80.html#phd_Schu_94">21</A>], road scene images
[<A
 HREF="node80.html#pr_Drap_87">22</A>], range imagesinterpretation,range image [<A
 HREF="node80.html#pr_Ozak_88">23</A>,<A
 HREF="node80.html#pr_Chel_90">24</A>,<A
 HREF="node80.html#bk_Agga_90">25</A>,<A
 HREF="node80.html#bk_Rame_90">26</A>], natural scene imagesinterpretation,natural scene [<A
 HREF="node80.html#pr_Stra_90">27</A>,<A
 HREF="node80.html#pr_Hild_93">28</A>],
color images interpretation,color images[<A
 HREF="node80.html#bk_Ohta_85">2</A>], infra red
imageryinterpretation,infra red images
[<A
 HREF="node80.html#pr_Silb_87">29</A>,<A
 HREF="node80.html#jr_Nand_88">30</A>], remotely sensed data imagesinterpretation,
remote sense images[<A
 HREF="node80.html#jr_Tayl_86">31</A>,<A
 HREF="node80.html#pr_Clem_92">32</A>], seismic data imagesinterpretation, seismic images[<A
 HREF="node80.html#jr_Zhan_87">33</A>], SAR images interpretation, SAR images
[<A
 HREF="node80.html#pr_Hell_92">34</A>], laser radar images interpretation, laser radar images
[<A
 HREF="node80.html#jr_Cchu_91">35</A>], astronomical
image interpretation, astronomical images[<A
 HREF="node80.html#jr_Kurt_90">36</A>], thermal images 
interpretation, thermal images [<A
 HREF="node80.html#jr_Nand_88">30</A>], ultra sound interpretation, ultra sound images
images [<A
 HREF="node80.html#pr_Towe_88">37</A>,<A
 HREF="node80.html#jr_Bald_92">10</A>], geophysical images interpretation,
geophysical images
[<A
 HREF="node80.html#jr_Robe_89">38</A>]. Interpretation based on multiple images like 
stereo [<A
 HREF="node80.html#pr_Sugi_88">39</A>,<A
 HREF="node80.html#jr_Pid_90">40</A>], sequence of 
moving images [<A
 HREF="node80.html#jr_Guil_85">41</A>,<A
 HREF="node80.html#jr_Mila_91">42</A>], moving viewer
[<A
 HREF="node80.html#pr_Tsui_88">43</A>] images have also been reported in literature.

<P>
Early work on image interpretation was based largely on isolated image
featuresisolated features
 and these salient features were classified  into a finite set
of classes, namely, interpretation labels,  presumably this scheme is
not robust especially when the low-level vision tasks give out an
erroneous output. More recent approaches adopt knowledge based systems
for image interpretationinterpretation,knowledge based. 
Here, a great amount of non-image related
knowledge underlying the scene representation is used along with the
spatial constraints.  Thus, even an ambiguous object can be recognized
based on the successful recognition of its neighborhood objects.

<P>
The early work in knowledge based image interpretation is summarized in
Nago and Matsuyama [<A
 HREF="node80.html#bk_Naga_80">13</A>], Binford [<A
 HREF="node80.html#jr_Binf_82">44</A>], Ohata
[<A
 HREF="node80.html#bk_Ohta_85">2</A>], Smyrniotis [<A
 HREF="node80.html#pr_Smyr_88">45</A>], Ballard
[<A
 HREF="node80.html#pr_Ball_xx">46</A>], Draper [<A
 HREF="node80.html#pr_Drap_87">22</A>], Mitiche [<A
 HREF="node80.html#pr_Miti_88">47</A>] and
more recently by Chu [<A
 HREF="node80.html#jr_Cchu_91">35</A>,<A
 HREF="node80.html#jr_Cchu_92">48</A>] and for man made
objects like office buildings and houses in an aerial images by Schutte
[<A
 HREF="node80.html#phd_Schu_94">21</A>]. Rule based strategies are especially appropriate in
view of lack of complete models and algorithmic strategies
[<A
 HREF="node80.html#jr_Zhan_87">33</A>,<A
 HREF="node80.html#bk_Scha_89">1</A>,<A
 HREF="node80.html#jr_Robe_93">49</A>,<A
 HREF="node80.html#jr_Puli_93">50</A>]. 

<P>
Various other approaches have been successfully used for image interpretation.
For example Fourier domain has
been used by Andrews for automatic 
interpretationinterpretation, Fourier domain and classification of images
[<A
 HREF="node80.html#bk_Andr_69">5</A>]. 
Heller and others [<A
 HREF="node80.html#pr_Hell_92">34</A>] 
use projective invariants and deformable templates for
interpretation. projective invariants interpretation, deformable
template interpretation of synthetic aperture radar (SAR) images.  
cellular automata to interpret patterns in human melanomas has been used
by Smolle and others
interpretation,cellular automata
[<A
 HREF="node80.html#jr_Smol_94">51</A>], morphometric and densitometric approach
has been used by Evangelista and Salvetti [<A
 HREF="node80.html#jr_Evan_93">52</A>] for image interpretation. Bayesian networks Bayesian and probabilistic networks have been 
used for the purpose of image interpretation [<A
 HREF="node80.html#jr_Dick_91">53</A>,<A
 HREF="node80.html#jr_Jens_92">54</A>,<A
 HREF="node80.html#pr_Bish_92">55</A>,<A
 HREF="node80.html#jr_Kuma_96">56</A>]. Wilhelmi algebraic topology [<A
 HREF="node80.html#jr_Wilh_92">57</A>] 
proposed an interpretation scheme based on algebraic topology. Of late,
Markov Random Field (MRF) interpretation, Markov random field models are being used for image interpretation
with the view to make the interpretation systematic and domain
independent
[<A
 HREF="node80.html#jr_Mode_92">58</A>,<A
 HREF="node80.html#jr_Kim_93">59</A>,<A
 HREF="node80.html#jr_Kuma_96">56</A>].  Most of the interpretation
schemes assume the availability of a good segmented image of the scene a
priori.  But in practice obtaining a <EM>good</EM> segmented image is
difficult for the simple reason that segmentation itself depends on
interpretation and hence is a function of the output of interpretation. 

<P>
Experiments conducted by Tenenbaum and Barrow [<A
 HREF="node80.html#jr_Tene_77">60</A>], where they
experiment on the use of interpretation to guide segmentation, indicate
the first possible use of interaction between the interpretation and
segmentation modules. 
Though their requirement was to segment an image, we
see that it was a good step, till then though it was known that
both segmentation and interpretation were related, the fact was not 
exploited. Later
there was discussion in this regard by Bajcsy in [<A
 HREF="node80.html#bk_Ruze_90">61</A>].
Sonka et al [<A
 HREF="node80.html#jr_Sonk_93">62</A>] have integrated segmentation and
interpretation into a single feedback process that incorporates
contextual knowledge. They use genetic 
algorithm interpretation,genetic algorithm to produce an
optimal image interpretationoptimal interpretation. More recently,  Kim and Yang
[<A
 HREF="node80.html#jr_Kim_93">59</A>] integrate segmentation and interpretation by forming a
combined weighted energy function; the segmentation block is weighted
high initially and as the algorithm iterates the weights shift to the
interpretation block.  

<P>
In Chapter <A HREF="node55.html#chap:joint_seg_mrf">7</A>, 
we propose a scheme for joint segmentation and image segmentation
interpretation in a multiresolution framework. 
 Unlike earlier work in multiresolution interpretation
[<A
 HREF="node80.html#pr_Silb_88">16</A>] we do not assume a priori, the availability of the 
segmented
image. In fact, in the proposed approach, segmentation and interpretation are
interleaved (modular integration)  and
the two operations are carried out at each resolution of the multiresolution
pyramid,
the idea being that the two operations while integrating, <EM>help</EM> each
other to perform better. The segmentation module helps the interpretation
module which in turn helps the segmentation module. 

<P>
<HR>
<A NAME="tex2html300"
  HREF="node9.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html296"
  HREF="node4.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html290"
  HREF="node7.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html298"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html301"
  HREF="node9.html">Approaches</A>
<B>Up:</B> <A NAME="tex2html297"
  HREF="node4.html">Overview</A>
<B> Previous:</B> <A NAME="tex2html291"
  HREF="node7.html">Image Interpretation</A>

<!--End of Navigation Panel-->
<ADDRESS>
<I> <BR>
2004-02-10</I>
</ADDRESS>
</BODY>
</HTML>
