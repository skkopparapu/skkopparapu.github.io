<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Approaches</TITLE>
<META NAME="description" CONTENT="Approaches">
<META NAME="keywords" CONTENT="kmono">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="kmono.css">

<LINK REL="next" HREF="node10.html">
<LINK REL="previous" HREF="node8.html">
<LINK REL="up" HREF="node4.html">
<LINK REL="next" HREF="node10.html">
</HEAD>

<BODY >

<A NAME="tex2html312"
  HREF="node10.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html308"
  HREF="node4.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html302"
  HREF="node8.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html310"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html313"
  HREF="node10.html">Layout of the Monograph</A>
<B>Up:</B> <A NAME="tex2html309"
  HREF="node4.html">Overview</A>
<B> Previous:</B> <A NAME="tex2html303"
  HREF="node8.html">Literature Review</A>
<BR> <P>

<!--End of Navigation Panel-->

<H1><A NAME="SECTION00440000000000000000">
Approaches</A>
</H1> interpretation, approaches
<A NAME="sec:interpretation_approaches"></A>
<P>
Image interpretation has been an active area of research for the past
couple of decades. By and large most approaches fall in one of the
following categories:

<P>

<OL>
<LI><B>Classification based Approach:</B>
  This was the early and direct approach
    ([<A
 HREF="node80.html#bk_Gras_69">4</A>,<A
 HREF="node80.html#bk_Nara_69">6</A>,<A
 HREF="node80.html#jr_Scho_83">63</A>]) 
 where
  using isolated image features isolated features 
a region was accorded a semantic
  label. It neither exploited any interrelationship that existed between
  neighboring regions nor did it have a hierarchical decision scheme of 
  elimination   and acceptance.

<P>
</LI>
<LI><B>Knowledge Based Approach:</B> This has also been termed as an 
expert
  system or rule based system for image interpretation. By far the
  most popular approach followed by a large number of researchers.
  The monograph by Ohta [<A
 HREF="node80.html#bk_Ohta_85">2</A>] provides an excellent
  exposition on this topic. We cite some early and some recent papers 
  on knowledge based image interpretationinterpretation, knowledge based:
  [<A
 HREF="node80.html#bk_Naga_80">13</A>,<A
 HREF="node80.html#jr_Binf_82">44</A>,<A
 HREF="node80.html#pr_Mcke_87">15</A>,<A
 HREF="node80.html#pr_Drap_88">64</A>,<A
 HREF="node80.html#pr_Smyr_88">45</A>,<A
 HREF="node80.html#jr_Puli_93">50</A>,<A
 HREF="node80.html#phd_Schu_94">21</A>]. This is simply an illustrative list and by no
  means does justice to the large body of work that exist on knowledge
  based image interpretation. For a reasonably comprehensive list
  please see [<A
 HREF="node80.html#tr_Sunil_96">65</A>]. 

<P>
In this approach,  besides using
  various features for a given region, relationships between regions are
  also exploited. For example, there could be adjacency constraints,
  like the road can be adjacent to a side walk but the road need not
  be adjacent to the sky. Moreover, there would be
  nominal value for the ratio of the perimeter of the road and the
  perimeter common to the road and the sidewalk. More such features
  are described in Appendix <A HREF="node74.html#app:features">G</A>. Of course, the 
designer of the system
  has to develop rules for interpretationinterpretation, rules for
 based on features for the
  region under consideration and spatial constraints. 

<P>
One of the main drawback of this approach is its strong dependence on
  domain knowledge and the rigidity of rules. Thus, rule based image   
  interpretation systems tend
  to be non-robust. To an extent this problem can be overcome by
  incorporating uncertainty factors or one could use a
  fuzzy expert system.

<P>
</LI>
<LI><B>Probabilistic Approach:</B>  This is the approach that will be
interpretation, probabilistic approach  emphasized in this monograph. The main motivation for considering a
  probabilistic framework is to make the interpretation process less
  dependent on domain knowledge. Here too, features and spatial
  constraints are used. But now they are embedded in a probability
  distribution pdf function, thus  
they do not appear as rigid parameters as in
  the knowledge based system. Consequently, dependence on domain
  knowledge is reduced. 

<P>

<OL>
<LI><B>MRF Framework:</B> Modestino and Zhang [<A
 HREF="node80.html#jr_Mode_92">58</A>] 
introduce the Markov random interpretation, Markov random field
  field (MRF) framework for the image interpretation problem.
  A fundamental assumption they make is that the conditional
  probability of the interpretation variables given the domain
  knowledge and measurement on the observed image is a MRF. 
Later work
  using this framework also adhere to this assumption. The
  interpretation problem is then formulated as a MAP (maximum <EM>    a posteriori</EM>) estimation problem. 

<P>
Modestino and Zhang select the basis function for the clique
  potential in the MRF model, based on functions used in fuzzy set
  theory. In order to overcome the prior selection of the cliques
  potential function and characterization of domain knowledge in terms
  of certain fixed numbers, Kim and Yang [<A
 HREF="node80.html#jr_Kim_93">59</A>] proposed the use of
  neural networks interpretation, neural networks, 
in particular the multilayer perceptron (MLP)
  network,  for cliques potential functions. The MLP
  networks are trained using the features from a set of training
  images. Thus the neural network learns the domain knowledge and is
  represented by the weights in the  MLP network.

<P>
</LI>
<LI><B>Bayesian Networks:</B> Bayesian network Another path uses 
probabilistic reasoning - pioneered by Pearl
  [<A
 HREF="node80.html#jr_Pearl_86">66</A>], [<A
 HREF="node80.html#jr_Pearl_87">67</A>]. 
    Unfortunately there is no uniformity in naming
  probabilistic reasoning networks; they have been  referred to as
   Bayesian networks, causal networks, belief networks or 
independence 
   networks. We shall
  stick to Bayesian networks, only because this is the more widely
  used name. It should be noted that Bayesian networks are distinctly
  different from probabilistic expert systems. The fundamental
  distinction being that  Bayesian networks are directed from cause to
  effect, while expert systems (probabilistic or otherwise) are
  directed from effect to cause. For more on this please see Pearl
  [<A
 HREF="node80.html#bk_Pearl_88">68</A>] and Neapolitan [<A
 HREF="node80.html#bk_Neap_90">69</A>]. 

<P>
A few researchers (Jensen et al [<A
 HREF="node80.html#jr_Jens_92">54</A>], Mann and Binford
  [<A
 HREF="node80.html#pr_Bish_92">55</A>], Kumar and Desai [<A
 HREF="node80.html#jr_Kuma_96">56</A>])
  have adopted this approach for image interpretation. In this monograph
  we present the approach of [<A
 HREF="node80.html#jr_Kuma_96">56</A>], since it deals with
  the image interpretation problem using   the MRF model and the
MAP
  estimation framework. Here,
  the MRF model is used to build a relative simple, singly connected, 
  two layered, Bayesian network for image interpretation. The domain
  knowledge is represented as the conditional probabilitiesconditional
probability of features
  given the interpretation, implying a soft dependence on domain
  knowledge. The converged state of the network represents the MAP
  estimate for the interpretation. 
  The Bayesian network is made to converge to its
  equilibrium state using a novel modification in the stochastic 
   simulation   algorithm of Pearl [<A
 HREF="node80.html#jr_Pearl_87">67</A>]; the novelty is in
  introducing an annealing schedule. 

<P>
</LI>
</OL> 

<P>
</LI>
<LI><B>Dempster-Shafer Evidential Reasoning [<A
 HREF="node80.html#bk_Shaf_76">70</A>]:</B>
  Dempster-Shafer theory of evidence has been advocated to overcome
  some of the limitations of probability theory; some authors have
  referred to this as an extension of probability theory
  [<A
 HREF="node80.html#pr_Horo_86">71</A>]. Though, we have not come across any work using
  this approach for image interpretation, we mention it here because
  it certainly does look like a possible approach for investigation; something
  future researchers in the field may want to consider.

<P>
</LI>
</OL>

<P>
All of the above approaches
 assumes that a segmented image, namely, an image
where regions to be interpreted are clearly demarcated, is
available. This is a very strong assumption, because it is well known
that segmentation is a difficult problem, and as yet a satisfactory
solution which works for a variety of images is illusive. In any case
the basic approach is sequentialsequential approach - 
segmentation followed by
interpretation 
(Figure <A HREF="node7.html#fig:basic_image_int_scheme_a">1.4(a)</A>). It seems reasonable to expect that
segmentation and interpretation should  operate in an interactive
manner - one should be able to help improve the results of the other
module. Some attempts have been made  in this direction.
The work of Tenenbaum and Barrow [<A
 HREF="node80.html#jr_Tene_77">60</A>] is
possibly the first attempt at tackling this problem. In recent times
there have not been much work in this direction. We mention the work of
Kim and Yang [<A
 HREF="node80.html#jr_Kim_95">72</A>], [<A
 HREF="node80.html#jr_Kim_96">73</A>], where they propose an 
energy
function in the MRF framework, which consists of two parts: one
corresponding to segmentation and the other corresponding to
interpretation. The segmentation part has a higher weight initially and
as the iteration progress the interpretation block receives higher
weight.

<P>
We have developed an integrated segmentation and 
interpretation 
scheme [<A
 HREF="node80.html#jr_Suni_98b">74</A>] using the
multiresolution framework coupled with the MRF 
framework (Chapter <A HREF="node55.html#chap:joint_seg_mrf">7</A>). The wavelet
transform of the image is used to refine the segmentation obtained from
a standard algorithm, say, the k-means clustering algorithm. At each
resolution segmentation and interpretation are carried out in an
interactive manner; this information is then communicated to the next
finer resolution. The process continues till we reach the finest resolution.

<P>
<HR>
<A NAME="tex2html312"
  HREF="node10.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html308"
  HREF="node4.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html302"
  HREF="node8.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html310"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html313"
  HREF="node10.html">Layout of the Monograph</A>
<B>Up:</B> <A NAME="tex2html309"
  HREF="node4.html">Overview</A>
<B> Previous:</B> <A NAME="tex2html303"
  HREF="node8.html">Literature Review</A>

<!--End of Navigation Panel-->
<ADDRESS>
<I> <BR>
2004-02-10</I>
</ADDRESS>
</BODY>
</HTML>
