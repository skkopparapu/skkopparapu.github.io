<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Introduction</TITLE>
<META NAME="description" CONTENT="Introduction">
<META NAME="keywords" CONTENT="kmono">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="kmono.css">

<LINK REL="next" HREF="node57.html">
<LINK REL="previous" HREF="node55.html">
<LINK REL="up" HREF="node55.html">
<LINK REL="next" HREF="node57.html">
</HEAD>

<BODY >

<A NAME="tex2html931"
  HREF="node57.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html927"
  HREF="node55.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html921"
  HREF="node55.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html929"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html932"
  HREF="node57.html">Image Interpretation using Integration</A>
<B>Up:</B> <A NAME="tex2html928"
  HREF="node55.html">Joint Segmentation and Image</A>
<B> Previous:</B> <A NAME="tex2html922"
  HREF="node55.html">Joint Segmentation and Image</A>
<BR> <P>

<!--End of Navigation Panel-->

<H1><A NAME="SECTION00810000000000000000"></A>
<A NAME="sec:scene_intro"></A>
<BR>
Introduction
</H1>

<P>
Though considerable amount of work has been done in the area of image
interpretation one is still on the lookout for a fully automated image
interpretation scheme. Automatic scene interpretation requires the
construction of at least a partial description of the original
environment, rather than a description of the image itself. It involves,
not only labelling certain regions in an image, or locating a single
object in the viewed scene, but often requires a 3D model of the
surroundings, with associated identification in the 2D image. 

<P>
For high-level interpretation, the principle unit of information is a
symbolic description of an object, or a set of image events, sometimes
referred to as symbolic tokens, extracted from the image. The description
includes relationships to other 2D symbolic tokens extracted from
the sensory data, such as lines, segments and other objects in the 3D
scene being viewed. It also includes pointers to elements of general
knowledge that has been used to support the interpretation process.

<P>
As shown earlier in Figure <A HREF="node7.html#fig:ii_overview">1.3</A>, the task of image interpretation
would essentially involve the task of segmenting (not shown in Figure 
<A HREF="node7.html#fig:ii_overview">1.3</A>) the image to produce
regions which have some <EM>relation</EM> to the objects in the scene and
then using some a priori knowledge to interpret, regions in the segmented
image. 
The image interpretation task is very much dependent on the a
priori knowledge, in the sense, knowledge acquired from an image should
bear <EM>resemblance</EM> to the image that is being interpreted. In other
words, the knowledge must have been acquired from an image which belongs to
the <EM>same class</EM> as the image that is being interpreted. 
<P>
<DIV><B>Note  5.1</B> &nbsp; 
In
literature, this aspect of image interpretation has either been taken for
granted or not addressed at all; in this sense the task of image
interpretation is nowhere close to being called fully automated. </DIV><P></P>

<P>
The need for image interpretation can be found in many diverse fields of 
science and engineering (see Section <A HREF="node8.html#sec:scene_litsurvey">3</A>, Chapter
<A HREF="node4.html#chapter:introduction"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="file:/usr/share/latex2html/icons/crossref.gif"></A>).
Traditionally, the task of image interpretation is performed by 
experienced human experts. However, analyzing a complex image is quite 
labor intensive, hence, much of the research is directed towards 
constructing automated image interpretation systems. Recent research in 
intelligent robots has created yet another need for automated image 
interpretation. In this case, the requirement is to understand what the 
robots see with the imaging sensors to be able to perform intelligent 
task in complex environments. Here, the robots have to rely entirely on 
automated image interpretation.

<P>
As seen in Section <A HREF="node9.html#sec:interpretation_approaches">4</A> of 
Chapter <A HREF="node4.html#chapter:introduction"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="file:/usr/share/latex2html/icons/crossref.gif"></A>,
the main approach in early research in image interpretation was that of
classification, in which, isolated image primitives were classified into a
finite set of object classes according to their feature measurements. 
However, since low-level processing often produces erroneous or incomplete
primitives, and the noise in the image may cause measurement errors in the
features, the performance of the image interpretation systems using the
classification approach is quite limited and prone to mistakes. The main
problem here is that the rich knowledge in the spatial relationships 
that
the human expert use is not used in the process of image interpretation. 

<P>
In this chapter, we propose a scheme for joint segmentation and 
image
interpretation in a multiresolution framework. 
 Unlike earlier work in multiresolution interpretation
[<A
 HREF="node80.html#pr_Silb_88">16</A>] we do not assume a priori, the availability of the 
segmented
image. In fact, in our approach, segmentation and interpretation processes or
modules are
interleaved (modular integration) as shown in Figure <A HREF="node56.html#fig:scheme">5.1</A> and
the two operations are carried out at each resolution of 
a multiresolution pyramid
the idea being that the two operations while synegetically 
integrating, <EM>help</EM> each
other to perform better. The segmentation module helps the interpretation
module which in turn helps the segmentation module. 

<P>

<DIV ALIGN="CENTER"><A NAME="fig:scheme"></A><A NAME="11467"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.1:</STRONG>
Macro-level joint segmentation and image interpretation scheme.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV>

<P>
<HR>
<A NAME="tex2html931"
  HREF="node57.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html927"
  HREF="node55.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html921"
  HREF="node55.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html929"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html932"
  HREF="node57.html">Image Interpretation using Integration</A>
<B>Up:</B> <A NAME="tex2html928"
  HREF="node55.html">Joint Segmentation and Image</A>
<B> Previous:</B> <A NAME="tex2html922"
  HREF="node55.html">Joint Segmentation and Image</A>

<!--End of Navigation Panel-->
<ADDRESS>
<I> <BR>
2004-02-10</I>
</ADDRESS>
</BODY>
</HTML>
