<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Knowledge Pyramid</TITLE>
<META NAME="description" CONTENT="Knowledge Pyramid">
<META NAME="keywords" CONTENT="kmono">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="kmono.css">

<LINK REL="previous" HREF="node78.html">
<LINK REL="up" HREF="node66.html">
<LINK REL="next" HREF="node80.html">
</HEAD>

<BODY >

<A NAME="tex2html1219"
  HREF="node80.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html1215"
  HREF="node66.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html1211"
  HREF="node78.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html1217"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html1220"
  HREF="node80.html">Bibliography</A>
<B>Up:</B> <A NAME="tex2html1216"
  HREF="node66.html">Conclusions</A>
<B> Previous:</B> <A NAME="tex2html1212"
  HREF="node78.html">Acquired Knowledge</A>
<BR> <P>

<!--End of Navigation Panel-->

<H1><A NAME="SECTION00970000000000000000">
Knowledge Pyramid</A>
</H1>

<P>
It is often required to be able to acquire knowledge at different resolutions.
Thought it is possible to acquire knowledge in the way described in this
appendix for all resolutions, in practise the knowledge acquizition becomes
difficult at coarser resolution. It is often useful to 
construct the knowledge at coarser resolution from the knowledge aquired at a
fine resolution using 
the rules tabulated
in Table <A HREF="node79.html#tab:rules_know">H.3</A>. 

<P>
<BR><P></P>
<DIV ALIGN="CENTER"><A NAME="16522"></A>
<TABLE>
<CAPTION><STRONG>Table H.3:</STRONG>
Rules for constructing knowledge pyramid.</CAPTION>
<TR><TD>
<DIV ALIGN="CENTER">
<TABLE CELLPADDING=3 BORDER="1" ALIGN="CENTER">
<TR><TD ALIGN="LEFT">features</TD>
<TD ALIGN="LEFT"><!-- MATH
 ${\cal{K}}^{\Omega -k}$
 -->
</TD>
<TD ALIGN="LEFT"><!-- MATH
 ${\cal{K}}^{\Omega -k-1}$
 -->
</TD>
</TR>
<TR><TD ALIGN="LEFT">area</TD>
<TD></TD>
<TD></TD>
</TR>
<TR><TD ALIGN="LEFT">perimeter</TD>
<TD ALIGN="LEFT">P</TD>
<TD ALIGN="LEFT">P/2</TD>
</TR>
<TR><TD ALIGN="LEFT">average gray value</TD>
<TD ALIGN="LEFT">G</TD>
<TD ALIGN="LEFT">G</TD>
</TR>
<TR><TD ALIGN="LEFT">mass center</TD>
<TD ALIGN="LEFT">M</TD>
<TD ALIGN="LEFT">M/2</TD>
</TR>
<TR><TD ALIGN="LEFT">variance</TD>
<TD ALIGN="LEFT">V</TD>
<TD ALIGN="LEFT">V</TD>
</TR>
<TR><TD ALIGN="LEFT">compactness</TD>
<TD ALIGN="LEFT">C</TD>
<TD ALIGN="LEFT">C</TD>
</TR>
<TR><TD ALIGN="LEFT">contrast</TD>
<TD ALIGN="LEFT">CR</TD>
<TD ALIGN="LEFT">CR</TD>
</TR>
<TR><TD ALIGN="LEFT">common perimeter ratio</TD>
<TD ALIGN="LEFT">CPR</TD>
<TD ALIGN="LEFT">CPR</TD>
</TR>
</TABLE>
</DIV>

<A NAME="tab:rules_know"></A></TD></TR>
</TABLE>
</DIV><P></P>
<BR>
HMM for Clique Functions
<A NAME="app:hmm_construction"></A>
<P>
<B>HMM for Single Node Clique to represent shape feature</B>
 
   Multiresolution signal decomposition based on the  
discrete wavelet
transform (DWT) is utilized to represent the shape of
the object at different scales. The shape of the object is encoded by HMM
by first obtaining the contour of the object. The contour is represented
as a sequence <!-- MATH
 $S = s_1, \cdots, s_\b = \{s_i\}_{i=1}^{\b }$
 -->
 where  is
the
total number of boundary points. 
  Each  is represented in the polar coordinate system with centroid
of
the object as the origin, namely,
 <BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
s_i = (r(s),\theta(s)) \stackrel{\rm def}{=}(r_i,\theta_i)
\end{displaymath}
 -->


</DIV>
<BR CLEAR="ALL">
<P></P>
where,  is the distance along the contour in the direction of
traversal.  To make the representation scale invariant, all the
components of  and <!-- MATH
 $\Theta=\{\theta_i\}$
 -->
 are normalized,
namely,
 <BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
r_i := \frac{r_i}{r_{\mbox{max}}} , \;\;\; 
           \theta_i := \frac{\theta_i}{\theta_{\mbox{max}}}
 %%
 -->


</DIV>
<BR CLEAR="ALL">
<P></P>
The DWT of the sequence  is found from scales 
<!-- MATH
 $0,\,\cdots,\,n_r$
 -->
. Similarly  the DWT of the sequence 
 is found from scales <!-- MATH
 $0, \cdots , n_\theta$
 -->
. 
 Now the feature vector used for training the HMM is constructed as
follows
 <BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
X(i)  = 
[r^{0}_{i},\,\cdots,\, r^{n_r}_{i},\,\theta^{0}_{i},\,\cdots,\,
\theta^{n_\theta}_{i}]^T
\end{displaymath}
 -->


</DIV>
<BR CLEAR="ALL">
<P></P>
 where  is the  component in the DWT of the
sequence  at scale <IMG
 WIDTH="23" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="img154.gif"
 ALT="$k$">, and similarly <!-- MATH
 $\theta^{k}_{i}$
 -->
 is the 
component in the DWT of  at scale <IMG
 WIDTH="23" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="img154.gif"
 ALT="$k$">. This set of feature vectors
provide a representation of the object at different scales. Thus, 
the shape model obtained is robust enough to withstand distortion, 
data
perturbation or noise in the data. 
 The sequence <!-- MATH
 $\{X(i)\}_{i=1}^{\b }$
 -->
 will not be rotation invariant
rotationally invariant. In
order to achieve rotation invariance we consider all rotated versions
of the sequence <!-- MATH
 $\{X(i)\}_{i=1}^{\b }$
 -->
. Consequently, all 
 the rotated sequences 
 <BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
X^{j} \stackrel{\rm def}{=}\{ X(j), \, X(j+1), \, \cdots \, , \, X(j-2), \, X(j-1) \}
\end{displaymath}
 -->


</DIV>
<BR CLEAR="ALL">
<P></P>
 for <!-- MATH
 $j = 1, \cdots, \b$
 -->
, constitute an equivalent training sequence for
the shape based HMM.

<P>
<B>HMM for Multiple Node Cliques - <EM>Joint HMM</EM>:</B>
    Spatial relationships spatial relationship
 between adjacent regions in an image can be
modeled using multiple node cliques. 
A new method for modeling adjacency
relationships using <EM>joint HMM</EM> joint HMM is described below. 

<P>
Consider a two node clique and let  
   and  represent the two adjacent regions in the segmented
image.  We build HMMs , <A NAME="tex2html56"
  HREF="footnode.html#foot16729"><SUP><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]"
 SRC="file:/usr/share/latex2html/icons/footnote.gif"></SUP></A> for a specific feature (say shape) corresponding to regions
 and  respectively.
 Since the regions are adjacent, there exists what we term as <EM>joint
HMM</EM> which gives information about the spatial relationship between the
two regions which is different from the information given by  and
 individually using the 
    following scheme:
 
<UL>
<LI>Let 
and  be two observation sequences generated using 
and  respectively. Construct a vector 
<BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
{\chi} = [ P(O_1, {I_2}^* \mid {{\cal H}_2}),P(O_2, {I_1}^* \mid
{{\cal H}_1}) ]^T
\end{displaymath}
 -->


</DIV>
<BR CLEAR="ALL">
<P></P>
where  denotes the optimal state sequence corresponding to the
observation , suppose that  was generated by , and similarly,  denotes the optimal
state sequence corresponding to the observation , suppose that
 was generated by  . 
 This can also be generalized to the case of a  clique clique,
-node where the
training vector becomes:  
 <BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
\begin{array}{ccc}
 {\chi} &=& [ P(O_1, {I_2}^* \mid {{\cal H}_2}),P(O_1, {I_3}^* \mid
{{\cal H}_3}),\cdots,P(O_1, {I_n}^* \mid {{\cal H}_n}) , \cdots,  \\
&& P(O_n, {I_1}^* \mid {{\cal H}_1}),P(O_n, {I_2}^* \mid {{\cal
H}_2}),\cdots,P(O_n, {I_{n-1}}^* \mid {{\cal H}_{n-1}})  ]^T 
\end{array}
\end{displaymath}
 -->


</DIV>
<BR CLEAR="ALL">
<P></P>
where,
<!-- MATH
 $O_1,\cdots,O_n$
 -->
 are the observation sequences generated using the HMMs 
<!-- MATH
 $\H_1, \cdots, \H_n$
 -->
 for an <EM>n-node</EM> clique.
Thus the vector  will be of dimension  for an 
<EM>n-node</EM> clique.

<P>
</LI>
<LI>This vector  is assumed to model the spatial relationship 
between the two sequences  and . The generated vector  
is then used as the observation sequence for training the two node clique
HMM. The number of states in this HMM is taken as the number of nodes in
the clique.  
 
</LI>
</UL>

<P>
The  spatial relations can thus be modeled
using HMMs, and the training observation sequences depend only on the HMMs
forming the clique. 

<P>

<HR>
<A NAME="tex2html1219"
  HREF="node80.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html1215"
  HREF="node66.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html1211"
  HREF="node78.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html1217"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html1220"
  HREF="node80.html">Bibliography</A>
<B>Up:</B> <A NAME="tex2html1216"
  HREF="node66.html">Conclusions</A>
<B> Previous:</B> <A NAME="tex2html1212"
  HREF="node78.html">Acquired Knowledge</A>

<!--End of Navigation Panel-->
<ADDRESS>
<I> <BR>
2004-02-10</I>
</ADDRESS>
</BODY>
</HTML>
