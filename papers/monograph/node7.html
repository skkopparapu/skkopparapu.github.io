<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Image Interpretation</TITLE>
<META NAME="description" CONTENT="Image Interpretation">
<META NAME="keywords" CONTENT="kmono">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="kmono.css">

<LINK REL="next" HREF="node8.html">
<LINK REL="previous" HREF="node5.html">
<LINK REL="up" HREF="node4.html">
<LINK REL="next" HREF="node8.html">
</HEAD>

<BODY >

<A NAME="tex2html288"
  HREF="node8.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html284"
  HREF="node4.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html278"
  HREF="node6.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html286"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html289"
  HREF="node8.html">Literature Review</A>
<B>Up:</B> <A NAME="tex2html285"
  HREF="node4.html">Overview</A>
<B> Previous:</B> <A NAME="tex2html279"
  HREF="node6.html">Scope of Computer Vision</A>
<BR> <P>

<!--End of Navigation Panel-->

<H1><A NAME="SECTION00420000000000000000">
Image Interpretation</A>
</H1>
Image interpretation, 
the theme of the monograph  is part of scene understanding; it can be 
viewed as
<EM>the process of giving meaning to a 2-D image by 
identifying and labelling significant objects or segments 
in the
image</EM>. For example we may first segment an image and then interpret
each segment as being a road, river, building, trees, vehicle,
etc. Consider the image in Figure <A HREF="node7.html#fig:sample_image">1.2</A>. 
It is a rather simple task for the human
visual system to discern that the image contains, a road, trees,
sidewalk, and sky. The objective of an image interpretation system is
to make the computer do the same.

<P>

<DIV ALIGN="CENTER"><A NAME="fig:sample_image"></A><A NAME="494"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 1.2:</STRONG>
Sample image to be interpreted, see text for details.</CAPTION>
<TR><TD><IMG
 WIDTH="365" HEIGHT="301" BORDER="0"
 SRC="img9.gif"
 ALT="\begin{figure}\centerline{\psfig{figure=Chap_1/images/sample_image.ps,width=0.35\textwidth}}\end{figure}"></TD></TR>
</TABLE>
</DIV>

<P>
Image interpretation is a high-level description of the environment
from which the image was taken. It is essentially an analysis problem
where we try to understand the image by identifying some important
features or objects in the image
 and analyze them depending on their spatial
relationship. Figure <A HREF="node7.html#fig:ii_overview">1.3</A> shows the task of image
interpretation.

<DIV ALIGN="CENTER"><A NAME="fig:ii_overview"></A><A NAME="502"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 1.3:</STRONG>
Overview of image interpretation task.</CAPTION>
<TR><TD><IMG
 WIDTH="194" HEIGHT="194" BORDER="0"
 SRC="img10.gif"
 ALT="\begin{figure}\centerline{\psfig{figure=Chap_5/images/over_view.ps,width=0.8\textwidth}}\end{figure}"></TD></TR>
</TABLE>
</DIV>

<P>
Image interpretation is a high-level description of the environment
from which the image was taken. It is essentially an analysis problem
where we try to understand the image by identifying some important
features or objects and analyze them depending on their spatial
relationship.
Interpretation must be in the form that is suitable for planning such
diverse activities as robot arm and hand motion, obstacle avoidance by
vehicle, aircraft navigation,  remote sensing or in biomedical
applications. Image interpretation is knowledge based processing, which
requires the  use of both low-level processing (image processing
techniques of contrast enhancement, computer vision techniques of
segmentation, feature extraction, region labelling) and high-level vision
tasks involving processing a great amount of non-image related
knowledge underlying the scene representation, for example, knowledge
about the world physical constraints influencing
entities [<A
 HREF="node80.html#bk_Scha_89">1</A>].  At low-level the basic processing unit
being pixel,  there is no simple computational transformation that will
map arrays of pixels onto stored symbolic concepts represented in the
high-level knowledge base. It is generally accepted that many stages of
processing must take place for reliable interpretation of a scene.

<P>
A typical image interpretation schemeinterpretation, scheme is shown in
Figure <A HREF="node7.html#fig:basic_image_int_scheme_a">1.4(a)</A> and 
consist of two interpretation, two block
blocks 
<DIV ALIGN="CENTER"><A NAME="fig:basic_image_int_scheme_a"></A><A NAME="fig:basic_image_int_scheme_b"></A><A NAME="fig:basic_image_int_scheme"></A><A NAME="765"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 1.4:</STRONG>
Basic image interpretation schemes.</CAPTION>
<TR><TD><IMG
 WIDTH="441" HEIGHT="140" BORDER="0"
 SRC="img11.gif"
 ALT="\begin{figure}\begin{center}
\subfigure[Two block scheme.]{
\vbox{\hspace*{-10ex...
...e}&lt;tex2html_endfile&gt; ..."></TD></TR>
</TABLE>
</DIV>
a low-level vision block (segmentation) which
segments the observed 2D image and  computes various 
features for
each segment. These features (Appendix <A HREF="node74.html#app:features">G</A> gives a 
list of features that can find use in image interpretation) 
could be based on gray level of the
segment (for example average gray level, texture, etc.) as well as the
shape of the segment (perimeter, area, compactness, etc.). The next
block (interpretation) is the one which provides the 
semantic description, namely, 
interpretation to each
segment of the image. This block has as its inputs, the <EM>domain
knowledge</EM> and the various features obtained from the low-level
vision block. More recently the trend is to look at the image interpretation
scheme as a three schemeinterpretation,three blocks 
(Figure <A HREF="node7.html#fig:basic_image_int_scheme_b">1.4(b)</A>) 
where in addition to segmentation 
and interpretation blocks we have a knowledge
acquisition blockinterpretation,block,knowledge acquisition which updates the domain knowledge base and gets its input from the
2-D scene and the segmentation block.

<P>
Domain knowledge domain knowledge is what represents 
a priori information
regarding various interpretations. For example, for a road we may
have the domain knowledge as: average gray level <IMG
 WIDTH="718" HEIGHT="929" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$= 70$">, standard
deviation of gray level <IMG
 WIDTH="40" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img13.gif"
 ALT="$= 7.32$">, and so on. It is to be noted that the
process of acquiring domain knowledge requires a fair amount of work 
(Appendix <A HREF="node76.html#sec:know_acq">H</A> 
describes one possible methodology to extract useful
knowledge):
in brief, one needs a set of sample images and on each image one needs to
perform manual segmentationsegmentation, manual. Next various  
features are computed on these
segments, and then the domain knowledge would be the average of
the feature value of  all the segments in all the images having the
same interpretation. An alternate way of characterizing the domain
knowledge is using the histogram for the features given the
interpretation, which is  used for the interpretation scheme based on
Bayesian networksinterpretation,Bayesian network 
as seen in Chapter <A HREF="node34.html#chap:bayes_net">1.2.3</A>. 

<P>
Information on acquiring domain knowledge can be obtained from the monograph of
Ohta [<A
 HREF="node80.html#bk_Ohta_85">2</A>] and [<A
 HREF="node80.html#tr_kumar_94">3</A>]. In Appendix <A HREF="node74.html#app:features">G</A> we
describe a simple procedure to extract domain knowledge corresponding to a human
face image.

<P>

<P>
<HR>
<A NAME="tex2html288"
  HREF="node8.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html284"
  HREF="node4.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html278"
  HREF="node6.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html286"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html289"
  HREF="node8.html">Literature Review</A>
<B>Up:</B> <A NAME="tex2html285"
  HREF="node4.html">Overview</A>
<B> Previous:</B> <A NAME="tex2html279"
  HREF="node6.html">Scope of Computer Vision</A>

<!--End of Navigation Panel-->
<ADDRESS>
<I> <BR>
2004-02-10</I>
</ADDRESS>
</BODY>
</HTML>
