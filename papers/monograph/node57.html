<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with jLaTeX2HTML 2002 (1.62) JA patch-1.4
patched version by:  Kenshi Muto, Debian Project.
LaTeX2HTML 2002 (1.62),
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Image Interpretation using Integration</TITLE>
<META NAME="description" CONTENT="Image Interpretation using Integration">
<META NAME="keywords" CONTENT="kmono">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="jLaTeX2HTML v2002 JA patch-1.4">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="kmono.css">

<LINK REL="next" HREF="node58.html">
<LINK REL="previous" HREF="node56.html">
<LINK REL="up" HREF="node55.html">
<LINK REL="next" HREF="node58.html">
</HEAD>

<BODY >

<A NAME="tex2html943"
  HREF="node58.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html939"
  HREF="node55.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html933"
  HREF="node56.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html941"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html944"
  HREF="node58.html">The Joint Segmentation and</A>
<B>Up:</B> <A NAME="tex2html940"
  HREF="node55.html">Joint Segmentation and Image</A>
<B> Previous:</B> <A NAME="tex2html934"
  HREF="node56.html">Introduction</A>
<BR> <P>

<!--End of Navigation Panel-->

<H1><A NAME="SECTION00820000000000000000"></A>
<A NAME="sec:ii_prob_form"></A>
<BR>
Image Interpretation using Integration
</H1>

<P>
The problem of image interpretation would essentially involve the 
low-level vision task of image segmentation to produce regions in the given
image corresponding to some objects in the scene and then giving some
labels or interpretation to the segmented regions based on some a priori
knowledge. Table <A HREF="node57.html#tab:ii_gen_inter">5.1</A>, shows the task of 
image interpretation in the framework of modular
integration[<A
 HREF="node80.html#phd_Suni_97">114</A>]. In
general, one is given an image which is a projection of a 3D scene onto
the 2D plane and some knowledge about the 3D environment. From the 2D
image we need to segment the image and interpret the regions based on the
segmented image.  This is shown in Figure <A HREF="node56.html#fig:scheme">5.1</A>, except for the
fact that the portions corresponding to <EM>wavelet transform</EM> and <EM>refine using difference image</EM> do not come into existence. 
<BR><P></P>
<DIV ALIGN="CENTER"><A NAME="11616"></A>
<TABLE>
<CAPTION><STRONG>Table 5.1:</STRONG>
Image interpretation using integration. </CAPTION>
<TR><TD>
<DIV ALIGN="CENTER">
<TABLE CELLPADDING=3 BORDER="1" ALIGN="CENTER">
<TR><TD ALIGN="LEFT">Modules</TD>
<TD ALIGN="LEFT">Feature</TD>
<TD ALIGN="LEFT">Knowledge</TD>
</TR>
<TR><TD ALIGN="LEFT">Integrated</TD>
<TD></TD>
<TD></TD>
</TR>
<TR><TD ALIGN="LEFT">(i) segmentation</TD>
<TD ALIGN="LEFT">gray levels,</TD>
<TD ALIGN="LEFT">nominal values of</TD>
</TR>
<TR><TD ALIGN="LEFT">(ii) image</TD>
<TD ALIGN="LEFT">scene based</TD>
<TD ALIGN="LEFT">gray level and shape</TD>
</TR>
<TR><TD ALIGN="LEFT">interpretation</TD>
<TD ALIGN="LEFT">features</TD>
<TD ALIGN="LEFT">based features, and</TD>
</TR>
<TR><TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">&nbsp;</TD>
<TD ALIGN="LEFT">spatial constraints</TD>
</TR>
</TABLE>
</DIV>
 
<A NAME="tab:ii_gen_inter"></A></TD></TR>
</TABLE>
</DIV><P></P>
<BR>
The task of image interpretation in the 
framework of modular integration and 
multiresolution
can be explicitly stated as: 

<P>
<BLOCKQUOTE>
Given the image <IMG
 WIDTH="29" HEIGHT="18" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.gif"
 ALT="$Y^\Omega $"> which is a projection of a 3D scene onto the 2D
plane at the finest resolution <IMG
 WIDTH="16" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img142.gif"
 ALT="$\Omega $">, defined over the 2D lattice of size
<!-- MATH
 $2^\Omega \times 2^\Omega$
 -->
<IMG
 WIDTH="13" HEIGHT="15" ALIGN="MIDDLE" BORDER="0"
 SRC="img149.gif"
 ALT="$2^\Omega \times
2^\Omega$">, and some knowledge  about the 3D environment.
The problem of interpretation involves
</BLOCKQUOTE>
<P>
<OL>
<LI>segmenting the image <IMG
 WIDTH="29" HEIGHT="18" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.gif"
 ALT="$Y^\Omega $"> to
obtain  and
</LI>
<LI>interpreting the image <IMG
 WIDTH="29" HEIGHT="18" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.gif"
 ALT="$Y^\Omega $">, based on the segmented image
 and the domain knowledge .
</LI>
</OL>
<P>

<P>
We now formulate the problem of image interpretation by synergistically
integrating both the segmentation segmentation module and the 
interpretation module interpretation modules in a
multiresolution framework. We term this procedure of interleaving
segmentation and interpretation procedures as <EM>joint segmentation and
interpretation</EM> joint segmentation and integration scheme. The idea of integrating these two operations is
two fold (i) both segmentation and interpretation modules by themselves do
not work efficiently because a good segmented image helps the
interpretation module perform better and to get a good segmentation,
knowledge of the scene, or in other words the interpretation of the scene
is essential, and (ii) we end up getting as a byproduct a <EM>better</EM>
segmented image in addition to a correctly interpreted image. The idea of
formulating this problem in a multiresolution framework is to speed up
computation as discussed in Section <A HREF="node22.html#sec:intro_multi">3</A> of Chapter
<A HREF="node11.html#chap:background">5</A>. 
<P>
<DIV><B>Note  5.2</B> &nbsp; 
Experimental results show that 
we need not work on the whole image but could stop at one level
coarser resolution while interpreting, namely if we need to interpret a
<!-- MATH
 $256 \times 256$
 -->
<IMG
 WIDTH="64" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img39.gif"
 ALT="$256 \times 256$"> image it is enough if we interpret a <!-- MATH
 $128 \times 128$
 -->
image. </DIV><P></P>

<P>

<DIV ALIGN="CENTER"><A NAME="fig:wt"></A><A NAME="11638"></A>
<TABLE>
<CAPTION ALIGN="BOTTOM"><STRONG>Figure 5.2:</STRONG>
Wavelet Transform representation of <IMG
 WIDTH="29" HEIGHT="18" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.gif"
 ALT="$Y^\Omega $">.</CAPTION>
<TR><TD></TD></TR>
</TABLE>
</DIV>

<P>
We  construct the wavelet transform of the image 
<IMG
 WIDTH="29" HEIGHT="18" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.gif"
 ALT="$Y^\Omega $">
[<A
 HREF="node80.html#jr_Mall_89">94</A>] which results in =<!-- MATH
 $D^{\Omega  -1}_{Y,LL}$
 -->
,
the low pass filter low pass filtered image and <!-- MATH
 $D^{\Omega  -1}_{Y,HL}$
 -->
, <!-- MATH
 $D^{\Omega
-1}_{Y,LH}$
 -->
, <!-- MATH
 $D^{\Omega  -1}_{Y,HH}$
 -->
 the difference image, each of size
<!-- MATH
 $2^{(\Omega-1)} \times 2^{(\Omega-1)}$
 -->
.  Figure <A HREF="node57.html#fig:wt">5.2</A> shows the
wavelet transformed structure of <IMG
 WIDTH="29" HEIGHT="18" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.gif"
 ALT="$Y^\Omega $">, where <!-- MATH
 $D^{\Omega  -1}_{Y,HL}$
 -->
(<!-- MATH
 $D^{\Omega  -1}_{Y,LH}$
 -->
) corresponds to the difference image obtained
when <IMG
 WIDTH="29" HEIGHT="18" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.gif"
 ALT="$Y^\Omega $"> is filtered by a high pass filter along the rows
(columns) and by a low pass filter along the columns (rows).
The low pass filtered image  is segmented using any
segmentation algorithm, segmentation algorithm. 
In this chapter for the purpose of simulations  we
have used the k-means clustering
algorithm (see Appendix <A HREF="node72.html#app:k_means">F</A>) to produce a crude segmented 
image. The segmented 
image is refined using the difference image (<!-- MATH
 $D^{\Omega -1}_{Y,HL}$
 -->
,
<!-- MATH
 $D^{\Omega-1}_{Y,LH}$
 -->
, <!-- MATH
 $D^{\Omega -1}_{Y,HH}$
 -->
) as described in Section
<A HREF="node58.html#sec:ii_scheme">3</A>.

<P>
The segmented image is subjected to interpretation. The problem of image
interpretation is formulated in a MRF framework along the lines described
in Section <A HREF="node29.html#sec:mrf_formulation_of_ii">1.1</A> of Chapter <A HREF="node26.html#chap:mrf_framework">3.2.1</A>
(similar to the formulation of Modestino and Zhang [<A
 HREF="node80.html#jr_Mode_92">58</A>]) 
except that we have a provision for
a <EM>no-interpretation</EM> label label, no-interpretation
. The reason for having <EM>no-interpretation</EM> label, as a possible label, is to refine the segmented
image before further interpretation can be carried out. The process of,
interpretation, merging of the <EM>no-interpretation</EM> labels to produce a
<EM>better</EM> segmented image and again interpretation, is carried out
until none of the regions have label <EM>no-interpretation</EM> (see Figure
<A HREF="node56.html#fig:scheme">5.1</A>). The resulting segmented image is assumed to be
the final segmented image and final interpretation is carried out on it.

<P>
At each resolution (say <IMG
 WIDTH="23" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="img154.gif"
 ALT="$k$">) let the segmented image (Figure
<A HREF="node27.html#RAG">3.1</A>) be
represented as an undirected simple planar graph. The nodes <!-- MATH
 $(R^k_1,
R^k_2, \cdots R^k_n)$
 -->
 representing the  regions of the segmented image at
resolution <IMG
 WIDTH="23" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="img154.gif"
 ALT="$k$">. 
Let the interpretation  be a
random variable associated with the region , <!-- MATH
 $j=1, \cdots, n$
 -->
,
and  takes a value from the label set 
<!-- MATH
 $\stackrel{\Delta}{=}$
 -->
,
where , , ,<IMG
 WIDTH="44" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="img145.gif"
 ALT="$\cdots$">,
 are the   possible labels.
<P>
<DIV><B>Note  5.3</B> &nbsp; 
 is the  <EM>no-interpretation</EM> label, and <!-- MATH
 $\{ \L _i^k \}_{i=1}^{m}$
 -->
 represent the 
possible 
interpretation labels</DIV><P></P>

<P>
Let 
 be the 
feature measurements made on the segmented image

and 
 be the domain knowledge at resolution <IMG
 WIDTH="23" HEIGHT="19" ALIGN="BOTTOM" BORDER="0"
 SRC="img154.gif"
 ALT="$k$">.
If we assume that the
conditional probability of , given  and
 is a Markov random field (MRF) MRF, namely,
<BR>
<DIV ALIGN="RIGHT">

<!-- MATH
 \begin{equation}
\P[{I^k}|F^k, {\cal{K}}^k]
=
\frac{1}{{\cal Z}^k} \exp^{-U({I^k};F^k, {\cal{K}}^k)}
\end{equation}
 -->
<TABLE WIDTH="100%" ALIGN="CENTER">
<TR VALIGN="MIDDLE"><TD ALIGN="CENTER" NOWRAP><A NAME="eq:max"></A></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(35)</TD></TR>
</TABLE>
<BR CLEAR="ALL"></DIV><P></P>
Now the image interpretation 
problem can be  posed as an optimization problem and the
optimal interpretation
label vector  is obtained by solving the MAP estimation problem,
namely,
 <BR>
<DIV ALIGN="CENTER">

<!-- MATH
 \begin{eqnarray}
I^k_{*}&= &arg \max_{{ I^k} \in
\{\L ^k\}} \P[{ I^k}|F^k, {\cal{K}}^k]  \nonumber \\
&=& arg \max_{{I^k} \in \{\L ^k\}}
\frac{1}{Z^k} \exp^{-U({ I^k};F^k, {\cal{K}}^k)}
\nonumber  \\&=& arg \min_{{ I^k} \in \{\L ^k\}}
U({I^k};F^k, {\cal{K}}^k)
\end{eqnarray}
 -->
<TABLE ALIGN="CENTER" CELLPADDING="0" WIDTH="100%">
<TR VALIGN="MIDDLE"><TD></TD>
<TD ALIGN="CENTER" NOWRAP><IMG
 WIDTH="128" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img82.gif"
 ALT="$\textstyle =$"></TD>
<TD></TD>
<TD WIDTH=10 ALIGN="RIGHT">
&nbsp;</TD></TR>
<TR VALIGN="MIDDLE"><TD NOWRAP ALIGN="RIGHT">&nbsp;</TD>
<TD ALIGN="CENTER" NOWRAP><IMG
 WIDTH="128" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img82.gif"
 ALT="$\textstyle =$"></TD>
<TD></TD>
<TD WIDTH=10 ALIGN="RIGHT">
&nbsp;</TD></TR>
<TR VALIGN="MIDDLE"><TD NOWRAP ALIGN="RIGHT">&nbsp;</TD>
<TD ALIGN="CENTER" NOWRAP><IMG
 WIDTH="128" HEIGHT="34" ALIGN="MIDDLE" BORDER="0"
 SRC="img82.gif"
 ALT="$\textstyle =$"></TD>
<TD></TD>
<TD WIDTH=10 ALIGN="RIGHT">
(36)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL"><P></P>
The problem of interpretation reduces to the problem of minimizing the
energy function <!-- MATH
 $U({I^k};F^k, {\cal{K}}^k)$
 -->
. The energy
function is constructed such that it takes a minimum value when the
interpretation labels are consistent with the knowledge  and the
feature measurements  derived from . The
minimization of the energy functional  <!-- MATH
 $F^k,
{\cal{K}}^k)$
 -->
 results in interpretation of the given scene.  Now,
<BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
U({I}^k;F^k, {\cal{K}}^k)  =
\sum_{c \in {\cal C}}V_c({I}^k;F^k, {\cal{K}}^k)
\end{displaymath}
 -->


</DIV>
<BR CLEAR="ALL">
<P></P>
where <!-- MATH
 $V_c(\cdot; \cdot, \cdot)$
 -->
's are the clique functions which
need to be constructed (see Section <A HREF="node30.html#sec:clique_selection">1.2</A>, 
Chapter <A HREF="node26.html#chap:mrf_framework">3.2.1</A>).
<P>
<DIV><B>Note  5.4</B> &nbsp; 
The clique function
should decrease when the interpretation labels are consistent with the 
domain knowledge and core variables, thus resulting in a decrease of the
energy function. This
means that the interpretation of the image that is <EM>most</EM> consistent
with the domain knowledge and core variables will have minimum energy. </DIV><P></P>

<HR>
<A NAME="tex2html943"
  HREF="node58.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.gif"></A> 
<A NAME="tex2html939"
  HREF="node55.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up.gif"></A> 
<A NAME="tex2html933"
  HREF="node56.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev.gif"></A> 
<A NAME="tex2html941"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/usr/share/latex2html/icons/contents.gif"></A>  <BR>
<B> Next:</B> <A NAME="tex2html944"
  HREF="node58.html">The Joint Segmentation and</A>
<B>Up:</B> <A NAME="tex2html940"
  HREF="node55.html">Joint Segmentation and Image</A>
<B> Previous:</B> <A NAME="tex2html934"
  HREF="node56.html">Introduction</A>

<!--End of Navigation Panel-->
<ADDRESS>
<I> <BR>
2004-02-10</I>
</ADDRESS>
</BODY>
</HTML>
